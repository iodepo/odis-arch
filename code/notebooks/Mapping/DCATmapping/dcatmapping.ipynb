{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b830de79",
   "metadata": {},
   "source": [
    "# Mapping - DCAT\n",
    "\n",
    "Testing approaches to mapping DCAT to schema.org\n",
    "\n",
    "For SPREP the profile and it's mapping to schema.org are found at https://resources.data.gov/resources/podm-field-mapping/#field-mappings and the source URL at: https://pacific-data.sprep.org/sites/default/files/pod_data/data.json\n",
    "\n",
    "## Current thinking\n",
    "\n",
    "* JSON-LD Frame with default values\n",
    "* SPARQL construct on these resulting frame to generate the new triples\n",
    "\n",
    "## Additional resources\n",
    "I wanted to highlight new resources available from the [FAIRsharing RDA Working Group](https://www.rd-alliance.org/group/fairsharing-registry-connecting-data-policies-standards-databases.html). See email below. In particular, they have released:\n",
    "* a [crosswalk](https://fairsharing.org/3641) of DCAT, Datacite, ISO 19115, and several other metadata standards to schema.org. (This is actually from the RDA Research Metadata Schemas WG …).\n",
    "* a new [registry of standards, databases, and data policies](https://fairsharing.org/)\n",
    "each of these is quite broad and worth perusing\n",
    "* an API for harvesting and modifying the records in the registry; see also some [documentation](https://fairsharing.gitbook.io/fairsharing/).\n",
    "\n",
    "\n",
    "## Mapping references\n",
    "\n",
    "* https://www.w3.org/2015/spatial/wiki/ISO_19115_-_DCAT_-_Schema.org_mapping\n",
    "* https://ec-jrc.github.io/dcat-ap-to-schema-org/\n",
    "* https://data.gov.au/data/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c.jsonld\n",
    "\n",
    "Note:  We should consider using the subjectOf property to link the generated schema.org to \n",
    "the source DCAT record where we can.  \n",
    "\n",
    "## Methodology\n",
    "\n",
    "We will load the DCAT JOSN-LD example and explore approaches to converting this to a form that can be used for \n",
    "schema.org.  \n",
    "\n",
    "Possible approaches include\n",
    "\n",
    "* Inferencing\n",
    "    * ref: https://derwen.ai/docs/kgl/infer/\n",
    "* SPARQL CONSTRUCT\n",
    "    * https://rdflib.readthedocs.io/en/stable/apidocs/rdflib.html\n",
    "    * https://derwen.ai/docs/kgl/ex4_0/\n",
    "* JSON-LD APIs\n",
    "    * https://w3c.github.io/json-ld-framing/#omit-default-flag\n",
    "* Context modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddcb27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kglab\n",
    "import json\n",
    "import rdflib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c1010e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load our JSON into a var to use later\n",
    "f = open('./data/dcatEx.json',)\n",
    "j = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbd0b4",
   "metadata": {},
   "source": [
    "## JSON-LD\n",
    "\n",
    "Use a frame to pull the elements we want to map, then alter the context for that \n",
    "frame or otehrwise cast to new namespace.\n",
    "\n",
    "Frame with defaults and then work to convert to new names space with SPARQL construct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f0275",
   "metadata": {},
   "source": [
    "## SPARQL CONSTRUCT example\n",
    "\n",
    "Refs:\n",
    "* https://derwen.ai/docs/kgl/ex4_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3c5bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N11e7a8aed3264f7c921e88a4dd434ff4 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecream import ic\n",
    "from pathlib import Path\n",
    "\n",
    "txt = Path('./data/dcatEx.json').read_text()\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(data=txt, format=\"json-ld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c767c76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparql = \"\"\"\n",
    "    SELECT ?s ?p ?o \n",
    "    WHERE {\n",
    "        ?s ?p ?o .\n",
    "    }\n",
    "    LIMIT 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c394d932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| row.asdict(): {'o': rdflib.term.Literal('Maranoa-Balonne-Condamine subregion'),\n",
      "                   'p': rdflib.term.URIRef('http://www.w3.org/ns/dcat#keyword'),\n",
      "                   's': rdflib.term.URIRef('https://data.gov.au/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c')}\n"
     ]
    }
   ],
   "source": [
    "for row in g.query(sparql):\n",
    "    ic(row.asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82310988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n    \"@context\": {\\n        \"@language\": \"en\",\\n        \"@vocab\": \"https://schema.org/\"\\n    },\\n    \"@id\": \"https://data.gov.au/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c\",\\n    \"identifier\": {\\n        \"@value\": \"67ca5de1-8774-4678-9d1b-8b1cb70ab33c\"\\n    }\\n}'\n"
     ]
    }
   ],
   "source": [
    "sparqlc = \"\"\"\n",
    " PREFIX dbpedia: <http://dbpedia.org/resource/>\n",
    " PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    " PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    " PREFIX dct: <http://purl.org/dc/terms/>\n",
    " PREFIX mo: <http://purl.org/ontology/mo/>\n",
    " PREFIX schema: <https://schema.org/>\n",
    "\n",
    "CONSTRUCT { \n",
    "       ?s schema:identifier ?o .\n",
    " }\n",
    " WHERE { \n",
    "       ?s dct:identifier ?o .\n",
    " }\n",
    "\"\"\"\n",
    "\n",
    "qres = g.query(sparqlc)\n",
    "context = {\"@vocab\": \"https://schema.org/\", \"@language\": \"en\"}\n",
    "print(qres.serialize(format='json-ld', context=context, indent=4))\n",
    "\n",
    "# g.parse(qres, format=\"nt\")\n",
    "    \n",
    "# for row in qres:\n",
    "#     print(\"-----\")\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02dcccaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kglab.kglab.KnowledgeGraph at 0x7fda4f11b790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kglab\n",
    "\n",
    "namespaces =  {\n",
    "    \"adms\": \"http://www.w3.org/ns/adms#\",\n",
    "    \"dcat\": \"http://www.w3.org/ns/dcat#\",\n",
    "    \"dct\": \"http://purl.org/dc/terms/\",\n",
    "    \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n",
    "    \"gsp\": \"http://www.opengis.net/ont/geosparql#\",\n",
    "    \"locn\": \"http://www.w3.org/ns/locn#\",\n",
    "    \"owl\": \"http://www.w3.org/2002/07/owl#\",\n",
    "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "    \"schema\": \"http://schema.org/\",\n",
    "    \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "    \"time\": \"http://www.w3.org/2006/time\",\n",
    "    \"vcard\": \"http://www.w3.org/2006/vcard/ns#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n",
    "  }\n",
    "\n",
    "kg = kglab.KnowledgeGraph(\n",
    "    name = \"DCAT example\",\n",
    "    base_uri = \"https://www.example.org/\",\n",
    "    namespaces = namespaces,\n",
    "    )\n",
    "\n",
    "kg.load_jsonld(\"./data/dcatEx.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7d739a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparql2 = \"\"\"\n",
    "    SELECT ?s  ?o \n",
    "    WHERE {\n",
    "        ?s dct:description ?o .\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bdbd6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "Pattern matched multiple keys",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOptionError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_347783/3045957219.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_option\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"max_rows\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_as_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msparql2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/_config/config.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 256\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__func__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/_config/config.py\u001B[0m in \u001B[0;36m_set_option\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 149\u001B[0;31m         \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_single_key\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msilent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m         \u001B[0mo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_registered_option\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/_config/config.py\u001B[0m in \u001B[0;36m_get_single_key\u001B[0;34m(pat, silent)\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mOptionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"No such keys(s): {repr(pat)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 116\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mOptionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Pattern matched multiple keys\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    117\u001B[0m     \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeys\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOptionError\u001B[0m: Pattern matched multiple keys"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"max_rows\", None)\n",
    "\n",
    "df = kg.query_as_df(sparql2)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe18569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pyvis_graph = kg.visualize_query(sparql2, notebook=True)\n",
    "# pyvis_graph.force_atlas_2based()\n",
    "# pyvis_graph.show(\"tmp.fig06.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29388297",
   "metadata": {},
   "source": [
    "## SHACL Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63cb1efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyshacl\n",
    "from pyshacl import validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd44199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#dateTime, Converter=<function parse_datetime at 0x7fdaaee87880>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 51, in parse_datetime\n",
      "    datestring, timestring = datetimestring.split('T')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.conda/envs/dev/lib/python3.10/site-packages/rdflib/term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 53, in parse_datetime\n",
      "    raise ISO8601Error(\"ISO 8601 time designator 'T' missing. Unable to\"\n",
      "isodate.isoerror.ISO8601Error: ISO 8601 time designator 'T' missing. Unable to parse datetime string '2019-03-21'\n",
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#dateTime, Converter=<function parse_datetime at 0x7fdaaee87880>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 51, in parse_datetime\n",
      "    datestring, timestring = datetimestring.split('T')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.conda/envs/dev/lib/python3.10/site-packages/rdflib/term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 53, in parse_datetime\n",
      "    raise ISO8601Error(\"ISO 8601 time designator 'T' missing. Unable to\"\n",
      "isodate.isoerror.ISO8601Error: ISO 8601 time designator 'T' missing. Unable to parse datetime string '2019-02-15'\n",
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#dateTime, Converter=<function parse_datetime at 0x7fdaaee87880>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 51, in parse_datetime\n",
      "    datestring, timestring = datetimestring.split('T')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.conda/envs/dev/lib/python3.10/site-packages/rdflib/term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 53, in parse_datetime\n",
      "    raise ISO8601Error(\"ISO 8601 time designator 'T' missing. Unable to\"\n",
      "isodate.isoerror.ISO8601Error: ISO 8601 time designator 'T' missing. Unable to parse datetime string '2019-05-21'\n",
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#dateTime, Converter=<function parse_datetime at 0x7fdaaee87880>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 51, in parse_datetime\n",
      "    datestring, timestring = datetimestring.split('T')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fils/.conda/envs/dev/lib/python3.10/site-packages/rdflib/term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"/home/fils/.local/lib/python3.10/site-packages/isodate/isodatetime.py\", line 53, in parse_datetime\n",
      "    raise ISO8601Error(\"ISO 8601 time designator 'T' missing. Unable to\"\n",
      "isodate.isoerror.ISO8601Error: ISO 8601 time designator 'T' missing. Unable to parse datetime string '2019-04-15'\n"
     ]
    }
   ],
   "source": [
    "conforms, v_graph, v_text = validate(data_graph=\"./data/learning.jsonld\", \n",
    "                shacl_graph='./shapes/oih_learning.ttl', \n",
    "                data_graph_format=\"json-ld\", \n",
    "                shape_graph_format=\"ttl\", \n",
    "                inference='none', \n",
    "                serialize_report_graph=\"json-ld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87931c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "b'[\\n  {\\n    \"@id\": \"_:N16694cb1bc104293bde5a11afa24cda0\",\\n    \"@type\": [\\n      \"http://www.w3.org/ns/shacl#ValidationReport\"\\n    ],\\n    \"http://www.w3.org/ns/shacl#conforms\": [\\n      {\\n        \"@value\": true\\n      }\\n    ]\\n  }\\n]'\n",
      "Validation Report\n",
      "Conforms: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conforms)\n",
    "print(v_graph)\n",
    "print(v_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "262a0fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyshacl import Validator\n",
    "\n",
    "# v = Validator(data_graph=dg_basin, shacl_graph=rule, options={\"inference\": \"rdfs\"},ont_graph=ont)\n",
    "# conforms, report_graph, report_text = v.run()\n",
    "# expanded_graph = v.target_graph \n",
    "\n",
    "df = Path('./data/data.ttl').read_text()\n",
    "dg = rdflib.Graph()\n",
    "dg.parse(data=df, format=\"ttl\")\n",
    "\n",
    "sf = Path('./shapes/shape.ttl').read_text()\n",
    "sg = rdflib.Graph()\n",
    "sg.parse(data=sf, format=\"ttl\")\n",
    "\n",
    "v = Validator(data_graph=dg, shacl_graph=sg,  options={\"inference\": \"none\", \"advanced\": True})  # turn off rdfs inferencing\n",
    "conforms, report_graph, report_text = v.run()\n",
    "expanded_graph = v.target_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d2110de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(conforms)\n",
    "# print(v_graph)\n",
    "# print(\"------------\")\n",
    "# print(v_text)\n",
    "# print(expanded_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee53f685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/ns#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ex:InvalidRectangle a ex:Rectangle .\n",
      "\n",
      "ex:NonSquareRectangle a ex:Rectangle ;\n",
      "    ex:height 2 ;\n",
      "    ex:width 3 .\n",
      "\n",
      "ex:SquareRectangle a ex:Rectangle,\n",
      "        ex:Square ;\n",
      "    ex:height 4 ;\n",
      "    ex:width 4 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(expanded_graph.serialize(format=\"ttl\")) #.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9178a",
   "metadata": {},
   "source": [
    "## Notes on SHACL AF Rules\n",
    "\n",
    "We need to add in PROV triples in this process to note the generation of these triples and\n",
    "the souce IRI tht results in the product IRI and the actor (?reference)\n",
    "\n",
    "Maybe review: https://www.w3.org/TR/2013/REC-prov-o-20130430/#qualifiedPrimarySource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e09b359-62e5-472d-a64b-57a67de46817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix ns1: <http://www.w3.org/ns/dcat#> .\n",
      "@prefix ns2: <http://www.w3.org/ns/locn#> .\n",
      "@prefix ns3: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix schema: <https://schema.org/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<https://data.gov.au/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c> a ns1:Dataset ;\n",
      "    dct:description \"a descriptiono of this dataset\" ;\n",
      "    dct:identifier \"67ca5de1-8774-4678-9d1b-8b1cb70ab33c\" ;\n",
      "    dct:issued \"2016-03-23T05:08:17.991412\"^^xsd:dateTime ;\n",
      "    dct:language \"eng\" ;\n",
      "    dct:modified \"2019-11-19T23:18:49.871451\"^^xsd:dateTime ;\n",
      "    dct:publisher <https://data.gov.au/organization/69f37b4c-bdf0-4c85-bd56-82fa6d6b087a> ;\n",
      "    dct:spatial [ a dct:Location ;\n",
      "            ns2:geometry \"POLYGON ((110.0012 -10.0012, 115.0080 -10.0012, 155.0080 -45.0036, 110.0012 -45.0036, 110.0012 -10.0012))\"^^<http://www.opengis.net/ont/geosparql#wktLiteral>,\n",
      "                \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[110.0012, -10.00117], [115.008, -10.00117], [155.008, -45.00362], [110.0012, -45.00362], [110.0012, -10.00117]]]}\"^^<https://www.iana.org/assignments/media-types/application/vnd.geo+json> ] ;\n",
      "    dct:title \"Dynamic Land Cover Dataset\" ;\n",
      "    ns1:distribution <https://data.gov.au/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c/resource/1f8174f8-573e-43f2-b110-3d1a13c380e8> ;\n",
      "    ns1:keyword \"Australia\",\n",
      "        \"Cooper subregion\",\n",
      "        \"LAND-Cover\",\n",
      "        \"Maranoa-Balonne-Condamine subregion\",\n",
      "        \"biota\",\n",
      "        \"environment\",\n",
      "        \"planningCadastre\" ;\n",
      "    schema:description \"a descriptiono of this dataset\" .\n",
      "\n",
      "<https://data.gov.au/dataset/67ca5de1-8774-4678-9d1b-8b1cb70ab33c/resource/1f8174f8-573e-43f2-b110-3d1a13c380e8> a ns1:Distribution ;\n",
      "    dct:description \"Data File\" ;\n",
      "    dct:format \"ZIP\" ;\n",
      "    dct:title \"Dynamic Land Cover Dataset\" ;\n",
      "    ns1:accessURL <https://datagovau.s3.amazonaws.com/bioregionalassessments/BA_ALL/ALL/DATA/Geography/LandCoverNDLC/1556b944-731c-4b7f-a03e-14577c7e68db.zip> ;\n",
      "    ns1:byteSize 186838338.0 .\n",
      "\n",
      "<https://data.gov.au/organization/69f37b4c-bdf0-4c85-bd56-82fa6d6b087a> a ns3:Organization ;\n",
      "    ns3:name \"Bioregional Assessment Program\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = Path('./data/dcat.ttl').read_text()\n",
    "dg = rdflib.Graph()\n",
    "dg.parse(data=df, format=\"turtle\")\n",
    "\n",
    "sf = Path('./shapes/dcatsdoOLD.ttl').read_text()\n",
    "sg = rdflib.Graph()\n",
    "sg.parse(data=sf, format=\"ttl\")\n",
    "\n",
    "v = Validator(data_graph=dg, shacl_graph=sg,  options={\"inference\": \"none\", \"advanced\": True})  # turn off rdfs inferencing\n",
    "conforms, report_graph, report_text = v.run()\n",
    "expanded_graph = v.target_graph \n",
    "\n",
    "output = str(expanded_graph.serialize(format=\"ttl\")) #.decode(\"utf-8\"))\n",
    "\n",
    "print(output)\n",
    "\n",
    "#save file\n",
    "# file = open(\"output.txt\", \"w\")\n",
    "# file.write(output)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47994e9-6711-4572-8bc6-f1e693069506",
   "metadata": {},
   "source": [
    "## Test with Pacific group style data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc4334a-39a0-41dc-9913-b4d96952e56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix : <https://project-open-data.cio.gov/v1.1/schema/> .\n",
      "@prefix dcat: <http://www.w3.org/ns/dcat#> .\n",
      "@prefix schema: <https://schema.org/> .\n",
      "\n",
      "<https://pacific-data.sprep.org/data.json> a dcat:Catalog ;\n",
      "    :conformsTo \"https://project-open-data.cio.gov/v1.1/schema\" ;\n",
      "    :dataset [ a dcat:Dataset ;\n",
      "            :accessLevel \"public\" ;\n",
      "            :accrualPeriodicity \"\" ;\n",
      "            :conformsTo \"\" ;\n",
      "            :contactPoint [ :fn \"pacific@dmin\" ;\n",
      "                    :hasEmail \"\" ] ;\n",
      "            :describedByType \"\" ;\n",
      "            :description \"Reports on the state of the world's sea turtles\" ;\n",
      "            :distribution [ :description \"In contrast to the properly grim outlook of just a few decades ago, these are pretty good times for sea turtles. In a 2017 paper titled “Global Sea Turtle Conservation Successes,” Antonio Mazaris and colleagues reported that published estimates of sea turtle populations tend to be increasing rather than decreasing globally. We have also seen the status of some species improving in recent Red List assessments led by the IUCN-SSC Marine Turtle Specialist Group, with both the leatherback and loggerhead improving to vulnerable globally (from critically endangered and endangered, respectively). Even the world’s most threatened sea turtle species—the Kemp’s ridley, which is still critically endangered— shows signs of a rebound (see pp. 32–33). Olive ridleys are smashing past abundance records at their arribada beach in Escobilla, Mexico, and SWOT Reports have shared many accounts of recovery, ranging from Michoacán black turtles (pp. 44–45), to the sea turtles of Japan (pp. 24–31) and Brazil, the Hawaiian honu, Cyprus greens, and loggerheads in Kyparissia Bay, Greece, to name a few.\" ;\n",
      "                    :downloadURL \"https://pacific-data.sprep.org/system/files/SWOT%20Report_13.pdf\" ;\n",
      "                    :format \"pdf\" ;\n",
      "                    :mediaType \"application/pdf\" ;\n",
      "                    :title \"State of the World's Sea Turtles (SWOT) Report XIII\" ] ;\n",
      "            :identifier \"d6c3ac2a-354f-430f-89df-392914a212c4\" ;\n",
      "            :isPartOf \"regional.pacificdata\" ;\n",
      "            :issued \"2021-07-21\" ;\n",
      "            :keyword \"2017\",\n",
      "                \"bycatch solution\",\n",
      "                \"french territories\",\n",
      "                \"pacific loggerheads\",\n",
      "                \"report\",\n",
      "                \"sea\",\n",
      "                \"sea turtle\",\n",
      "                \"swot\",\n",
      "                \"turtle\",\n",
      "                \"world\" ;\n",
      "            :landingPage \"https://pacific-data.sprep.org/dataset/state-worlds-sea-turtles\" ;\n",
      "            :language \"\" ;\n",
      "            :license \"cc-by-sa\" ;\n",
      "            :modified \"2022-02-11\" ;\n",
      "            :publisher [ a <org:Organization> ;\n",
      "                    :name \"Secretariat of the Pacific Regional Environment Programme\" ] ;\n",
      "            :relevantCountries \"Pacific Region\" ;\n",
      "            :theme \"Biodiversity\",\n",
      "                \"Coastal and Marine\" ;\n",
      "            :title \"The State of the World's Sea Turtles\" ;\n",
      "            schema:description \"Reports on the state of the world's sea turtles\" ],\n",
      "        [ a dcat:Dataset ;\n",
      "            :accessLevel \"public\" ;\n",
      "            :accrualPeriodicity \"\" ;\n",
      "            :conformsTo \"\" ;\n",
      "            :contactPoint [ :fn \"Clark Peteru\" ;\n",
      "                    :hasEmail \"clarkp@sprep.org\" ] ;\n",
      "            :describedByType \"\" ;\n",
      "            :description \"Summary table of the status of Pacific Island countries in relation to International and Regional conventions.\" ;\n",
      "            :distribution [ :downloadURL \"http://www.sprep.org/attachments/Publications/Corporate_Documents/mea-database-july-2017.pdf\" ;\n",
      "                    :format \"pdf\" ;\n",
      "                    :mediaType \"application/pdf\" ;\n",
      "                    :title \"MEA Database - July 2017\" ] ;\n",
      "            :identifier \"e698f50a-aad7-4696-b59f-17d32e719363\" ;\n",
      "            :isPartOf \"regional.pacificdata\" ;\n",
      "            :issued \"2021-07-21\" ;\n",
      "            :landingPage \"http://www.sprep.org/Multilateral-Environmental-Agreements/pacific-regional-clearinghouse-mechanism\" ;\n",
      "            :language \"\" ;\n",
      "            :license \"cc-by-sa\" ;\n",
      "            :modified \"2022-02-11\" ;\n",
      "            :publisher [ a <org:Organization> ;\n",
      "                    :name \"Secretariat of the Pacific Regional Environment Programme\" ] ;\n",
      "            :relevantCountries \"Pacific Region\" ;\n",
      "            :spatial \"POLYGON ((-217.14258670807 -30.695866237642, -217.14258670807 33.777934519888, -111.32227420807 33.777934519888, -111.32227420807 -30.695866237642))\" ;\n",
      "            :theme \"Atmosphere and Climate\",\n",
      "                \"Biodiversity\",\n",
      "                \"Built Environment\",\n",
      "                \"Coastal and Marine\",\n",
      "                \"Culture and Heritage\",\n",
      "                \"Inland Waters\",\n",
      "                \"Land\" ;\n",
      "            :title \"MEA Database\" ;\n",
      "            schema:description \"Summary table of the status of Pacific Island countries in relation to International and Regional conventions.\" ] ;\n",
      "    :describedBy \"https://project-open-dat…v1.1/schema/catalog.json\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = Path('./data/pacificTest.json').read_text()\n",
    "dg = rdflib.Graph()\n",
    "dg.parse(data=df, format=\"json-ld\")\n",
    "\n",
    "sf = Path('./shapes/dcatsdoOLD.ttl').read_text()\n",
    "sg = rdflib.Graph()\n",
    "sg.parse(data=sf, format=\"ttl\")\n",
    "\n",
    "v = Validator(data_graph=dg, shacl_graph=sg,  options={\"inference\": \"none\", \"advanced\": True})  # turn off rdfs inferencing\n",
    "conforms, report_graph, report_text = v.run()\n",
    "expanded_graph = v.target_graph \n",
    "\n",
    "output = str(expanded_graph.serialize(format=\"ttl\")) #.decode(\"utf-8\"))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc3872-5c24-4b5a-a876-6ab32d10ffd2",
   "metadata": {},
   "source": [
    "## Work on full collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28fec7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = Path('./data/datahub.json').read_text()\n",
    "dg = rdflib.Graph()\n",
    "dg.parse(data=df, format=\"json-ld\")\n",
    "\n",
    "sf = Path('./shapes/dcatsdoOLD.ttl').read_text()\n",
    "sg = rdflib.Graph()\n",
    "sg.parse(data=sf, format=\"ttl\")\n",
    "\n",
    "v = Validator(data_graph=dg, shacl_graph=sg,  options={\"inference\": \"none\", \"advanced\": True})  # turn off rdfs inferencing\n",
    "conforms, report_graph, report_text = v.run()\n",
    "expanded_graph = v.target_graph \n",
    "\n",
    "output = str(expanded_graph.serialize(format=\"ttl\")) #.decode(\"utf-8\"))\n",
    "\n",
    "#save file\n",
    "file = open(\"output.txt\", \"w\")\n",
    "file.write(output)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372492e4-6dd9-4967-aec9-cb0575e910a5",
   "metadata": {},
   "source": [
    "## JSON-LD frame to pull out the newly generated triples\n",
    "\n",
    "Need to generate a frame that will result in just the new triples being framed out.   Though not really required, it might be useful in some cases and would also allow us to better test the queries (or at least in a simpler manner).   Also the frame could populate in default values that might be harder with SHACL.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
