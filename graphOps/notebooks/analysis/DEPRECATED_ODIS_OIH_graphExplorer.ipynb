{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hRr85vigOiR"
   },
   "source": [
    "# ODIS / OIH RDF Graph Explorer\n",
    "\n",
    "In process RDF \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrxJQDSgxw1G"
   },
   "source": [
    "## Installs, imports and definitions\n",
    "\n",
    "### Try\n",
    "* https://kuzudb.com/docusaurus/blog/llms-graphs-part-1/\n",
    "* https://kuzudb.com/docusaurus/blog/transforming-your-data-to-graphs-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2ZDVJx4n4gf7"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q minio\n",
    "!pip install -q oxrdflib\n",
    "!pip install -q ipysigma\n",
    "!pip install --upgrade --pre kuzu\n",
    "!pip install -q pyoxigraph\n",
    "!pip install -q pygraphml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sI2_aqTs-gfa"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)  ## remove pandas future warning\n",
    "from minio import Minio\n",
    "from urllib.request import urlopen\n",
    "import kuzu\n",
    "from ipysigma import Sigma\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import networkx as nx\n",
    "from lxml import etree\n",
    "import io\n",
    "import pyoxigraph\n",
    "from rdflib import Graph\n",
    "\n",
    "from pygraphml import GraphMLParser\n",
    "from pygraphml import Graph as GraphML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7_EIoLaGj4e8"
   },
   "outputs": [],
   "source": [
    "def publicurls(client, bucket, prefix):\n",
    "    urls = []\n",
    "    objects = client.list_objects(bucket, prefix=prefix, recursive=True)\n",
    "    for obj in objects:\n",
    "        result = client.stat_object(bucket, obj.object_name)\n",
    "\n",
    "        if result.size > 0:  #  how to tell if an objet   obj.is_public  ?????\n",
    "            url = client.presigned_get_object(bucket, obj.object_name)\n",
    "            # print(f\"Public URL for object: {url}\")\n",
    "            urls.append(url)\n",
    "\n",
    "    return urls\n",
    "\n",
    "def download_file(url):\n",
    "    \"\"\"Downloads a remote file and handles potential errors.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)  # Stream for efficient memory usage\n",
    "        response.raise_for_status()  # Raise exception for error codes\n",
    "\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        local_filename = f\"./data/{filename.replace('.nq', '.nt')}\"  # Convert extension\n",
    "\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):  # Download in chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Download failed for {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G5BEhyL-25rb"
   },
   "outputs": [],
   "source": [
    "client = Minio(\"ossapi.oceaninfohub.org:80\",  secure=False) # Create client with anonymous access.\n",
    "urls = publicurls(client, \"commons\", \"OIH-KG/21022024/nt\")\n",
    "# for u in urls:\n",
    "#   print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMQttOx0Buob"
   },
   "source": [
    "## Copy files local for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "15Zi8NotSXtk"
   },
   "outputs": [],
   "source": [
    "# make the directory ./data if it doesn't exist\n",
    "# Define the directory path\n",
    "directory_path = \"./data\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(directory_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMnNFt8Lp3nj",
    "outputId": "480a3f1e-524f-4de7-8592-a9064a904ac1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloaded: inanodc_release.nt\n",
      "Downloaded: invemarvessels_release.nt\n",
      "Downloaded: invemarinstitutions_release.nt\n",
      "Downloaded: invemartraining_release.nt\n",
      "Downloaded: africaioc_release.nt\n",
      "Downloaded: bmdc_release.nt\n",
      "Downloaded: invemarexperts_release.nt\n",
      "Downloaded: emodnet_release.nt\n",
      "Downloaded: edmo_release.nt\n",
      "Downloaded: nmdis_release.ntDownloaded: marinetraining_release.nt\n",
      "\n",
      "Downloaded: oceanscape_release.nt\n",
      "Downloaded: edmerp_release.nt\n",
      "Downloaded: cioos_release.nt\n",
      "Downloaded: pedp_release.nt\n",
      "Downloaded: obps_release.nt\n",
      "Downloaded: obis_release.nt\n",
      "Downloaded: invemardocuments_release.nt\n",
      "Downloaded: oceanexpert_release.nt\n",
      "Downloaded: rda_release.nt\n",
      "Downloaded: medin_release.nt\n",
      "Downloaded: pdh_release.nt\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    for url in urls:\n",
    "        if \"_prov\" not in url:\n",
    "            executor.submit(download_file, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLxkSRC9EyFc"
   },
   "source": [
    "## Load to Oxigraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NSWj9oKWHvyq"
   },
   "outputs": [],
   "source": [
    "store = pyoxigraph.Store()  #    store = pyoxigraph.Store(path=\"./store\")\n",
    "mime_type = \"application/n-triples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wjyc-4xEE0AQ"
   },
   "outputs": [],
   "source": [
    "dir = \"./data\"\n",
    "for f in os.listdir(dir):\n",
    "  fp = os.path.join(dir, f)\n",
    "\n",
    "  store.load(io.StringIO(open(fp, 'r').read()), mime_type, base_iri=None, to_graph=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0poucxJzHZJ7"
   },
   "outputs": [],
   "source": [
    "rq1 = \"\"\"\tPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX schema: <https://schema.org/>\n",
    "\n",
    "SELECT DISTINCT ?source ?type ?target ?sType ?tType\n",
    "WHERE {\n",
    "    ?source a ?sType .\n",
    "    ?target a ?tType .\n",
    "    ?source ?type ?target .\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rq2 = 'SELECT ?s WHERE { ?s ?p ?o } LIMIT 100'\n",
    "\n",
    "rq3 = \"\"\"\tPREFIX schema: <https://schema.org/>\n",
    "SELECT ?o\n",
    "WHERE {\n",
    "     ?s schema:distribution ?d .\n",
    "     ?d schema:contentUrl ?o .\n",
    " }\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ic1_OjIUMej8"
   },
   "outputs": [],
   "source": [
    "qr = list(store.query(rq1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GGh47i2HMqRW"
   },
   "outputs": [],
   "source": [
    "# print(len(qr))\n",
    "# for r in qr[0:20]:\n",
    "#   # h = is_url_reachable(r['o'].value)\n",
    "#   # d = is_url_downloadable(r['o'].value)\n",
    "#   h = \"test;\"\n",
    "#   d = \"test;\"\n",
    "#   print(\"{} {} {}\".format(r['source'].value, r['target'].value, r['type'].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzLG3AE1lsM3"
   },
   "outputs": [],
   "source": [
    "#  yeah, I get it...   don't iterate rows...  PR's welcome for this, being bad is too easy!\n",
    "# for index, row in nodes.iterrows():\n",
    "#    g.add_node(row['Id'])\n",
    "g = GraphML()\n",
    "g.directed = False\n",
    "\n",
    "for  r in qr:\n",
    "    n1 = g.add_node(r['source'])\n",
    "    # n1['name'] = row['name']\n",
    "\n",
    "    n2 = g.add_node(r['target'])\n",
    "    # n2['type'] = \"Funder\"\n",
    "    # n2['value'] = row['funding.name']\n",
    "\n",
    "    # n3 = g.add_node(row['ahash'])\n",
    "    # n3['type'] = \"Affiliation\"\n",
    "    # n3['value'] = row['affil']\n",
    "\n",
    "    e1 = g.add_edge(n1, n2)\n",
    "    # e2 = g.add_edge(n1, n3)\n",
    "    # e['predicate'] = row['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9INYPLhm11Y"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mJ-QP4-kP2u"
   },
   "outputs": [],
   "source": [
    "fname = \"testGraphML.graphml\"\n",
    "parser = GraphMLParser()\n",
    "parser.write(g, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86QToejGkXDh"
   },
   "outputs": [],
   "source": [
    "g = nx.read_graphml(\"testGraphML.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLEo0QdvjUmQ"
   },
   "outputs": [],
   "source": [
    "Sigma(\n",
    "    g,\n",
    "    node_size=g.degree,\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    node_metrics=['louvain'],\n",
    "    node_color='louvain',\n",
    "    start_layout=5,\n",
    "    edge_size=lambda u, v: g.degree(u) + g.degree(v),\n",
    "    edge_size_range=(0.5, 5),\n",
    "    label_font='cursive',\n",
    "    node_label_size=g.degree,\n",
    "    label_density=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7W82L95nlnS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
