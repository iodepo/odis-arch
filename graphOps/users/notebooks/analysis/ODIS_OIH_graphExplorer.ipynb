{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ODIS / OIH RDF Graph Explorer\n",
    "\n",
    "In process RDF \n"
   ],
   "metadata": {
    "id": "6hRr85vigOiR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installs, imports and definitions\n"
   ],
   "metadata": {
    "id": "hrxJQDSgxw1G"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ZDVJx4n4gf7",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:12:33.243895Z",
     "start_time": "2024-06-22T20:12:05.723637Z"
    }
   },
   "source": [
    "# %%capture\n",
    "# !pip install -q minio\n",
    "# !pip install -q oxrdflib\n",
    "# !pip install -q ipysigma\n",
    "# !pip install -q kuzu\n",
    "# !pip install -q pyoxigraph\n",
    "# !pip install -q pygraphml"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)  ## remove pandas future warning\n",
    "from minio import Minio\n",
    "from urllib.request import urlopen\n",
    "import kuzu\n",
    "from ipysigma import Sigma\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import networkx as nx\n",
    "from lxml import etree\n",
    "import io\n",
    "import pyoxigraph\n",
    "import re\n",
    "from rdflib import Graph\n",
    "\n",
    "from pygraphml import GraphMLParser\n",
    "from pygraphml import Graph as GraphML"
   ],
   "metadata": {
    "id": "sI2_aqTs-gfa",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:13:22.016838Z",
     "start_time": "2024-06-22T20:13:21.340807Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from ast import mod\n",
    "\n",
    "# popper will convert nq to nt (via a simple hack), it will also convert http to https for schema.org prefixes\n",
    "def popper(input):\n",
    "    lines = input.splitlines()\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        newline = line.replace(\"http://schema.org\", \"https://schema.org\")\n",
    "        segments = newline.split(' ')\n",
    "\n",
    "        if len(segments) > 3:\n",
    "            segments.pop()   # Remove the last two segment\n",
    "            segments.pop()\n",
    "            new_line = ' '.join(segments) + ' .'\n",
    "            modified_lines.append(new_line)\n",
    "\n",
    "\n",
    "    # print(len(modified_lines))\n",
    "    result_string = '\\n'.join(modified_lines)\n",
    "    # print(len(result_string))\n",
    "\n",
    "    return(result_string)\n",
    "\n",
    "# prefalign will convert http to https for schema.org prefixes\n",
    "def prefalign(input):\n",
    "    lines = input.splitlines()\n",
    "    modified_lines = []\n",
    "\n",
    "    regex = re.compile(r'[\\r\\n\\t]+')\n",
    "\n",
    "    for line in lines:\n",
    "        new_line = line.replace(\"http://schema.org\", \"https://schema.org\")\n",
    "        new_string = re.sub(regex, ' ', new_line)\n",
    "        modified_lines.append(new_string)\n",
    "\n",
    "\n",
    "    # print(len(modified_lines))\n",
    "    result_string = '\\n'.join(modified_lines)\n",
    "    # print(len(result_string))\n",
    "\n",
    "    return(result_string)\n",
    "\n",
    "\n",
    "def publicurls(client, bucket, prefix):\n",
    "    urls = []\n",
    "    objects = client.list_objects(bucket, prefix=prefix, recursive=True)\n",
    "    for obj in objects:\n",
    "        result = client.stat_object(bucket, obj.object_name)\n",
    "\n",
    "        if result.size > 0:  #  how to tell if an objet   obj.is_public  ?????\n",
    "            url = client.presigned_get_object(bucket, obj.object_name)\n",
    "            # print(f\"Public URL for object: {url}\")\n",
    "            urls.append(url)\n",
    "\n",
    "    return urls\n",
    "\n",
    "def download_file(url):\n",
    "    \"\"\"Downloads a remote file and handles potential errors.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)  # Stream for efficient memory usage\n",
    "        response.raise_for_status()  # Raise exception for error codes\n",
    "\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        local_filename = f\"./data/{filename.replace('.nq', '.nt')}\"  # Convert extension\n",
    "\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):  # Download in chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Download failed for {url}: {e}\")"
   ],
   "metadata": {
    "id": "7_EIoLaGj4e8",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:13:23.152505Z",
     "start_time": "2024-06-22T20:13:23.147432Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "client = Minio(\"ossapi.oceaninfohub.org:80\",  secure=False) # Create client with anonymous access.\n",
    "urls = publicurls(client, \"commons\", \"ODIS-KG-MAIN/18042024\")\n",
    "# for u in urls:\n",
    "#   print(u)"
   ],
   "metadata": {
    "id": "G5BEhyL-25rb",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:13:27.792512Z",
     "start_time": "2024-06-22T20:13:24.324592Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Copy files local for use\n",
    "\n",
    "You could load over the network directory into the triplestore.  For other tools like Kuzu this is not currently an option so I have the code here to pull down the files first, then load them."
   ],
   "metadata": {
    "id": "pMQttOx0Buob"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the directory path\n",
    "directory_path = \"./data\"\n",
    "\n",
    "# Check if the directory exists and make it if it doesn't\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)"
   ],
   "metadata": {
    "id": "15Zi8NotSXtk",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:13:49.473968Z",
     "start_time": "2024-06-22T20:13:49.471964Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    for url in urls:\n",
    "        if \"_prov\" not in url:\n",
    "            executor.submit(download_file, url)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMnNFt8Lp3nj",
    "outputId": "4eeb0754-9fbf-4287-cd50-d97c58f56887",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:15:19.883879Z",
     "start_time": "2024-06-22T20:13:50.209157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: inanodc_release.nq\n",
      "Downloaded: oceanscape_release.nq\n",
      "Downloaded: invemarvessels_release.nq\n",
      "Downloaded: oceanexperts_release.nq\n",
      "Downloaded: invemarinstitutions_release.nq\n",
      "Downloaded: africaioc_release.nq\n",
      "Downloaded: invemartraining_release.nq\n",
      "Downloaded: invemarexperts_release.nq\n",
      "Downloaded: oceanexpert_release.nq\n",
      "Downloaded: euroceanevents_release.nq\n",
      "Downloaded: medin_release.nq\n",
      "Downloaded: obps_release.nq\n",
      "Downloaded: edmo_release.nq\n",
      "Downloaded: edmerp_release.nq\n",
      "Downloaded: wod_release.nq\n",
      "Downloaded: marinetraining_release.nq\n",
      "Downloaded: pedp_release.nq\n",
      "Downloaded: rda_release.nq\n",
      "Downloaded: euroceanexperts_release.nq\n",
      "Downloaded: obis_release.nq\n",
      "Downloaded: cioos_release.nq\n",
      "Downloaded: aquadocs_release.nq\n",
      "Downloaded: pdh_release.nq\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversion section if needed\n",
    "\n",
    "In this section you can call code to either convert nq to nt and or align the various schema.org prefix values."
   ],
   "metadata": {
    "id": "4DEND3pfPNzN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the directory path\n",
    "directory_path = \"./converted\"\n",
    "\n",
    "# Check if the directory exists and make it if it doesn't\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)"
   ],
   "metadata": {
    "id": "w3Plw_aPPsMJ",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:15:49.502274Z",
     "start_time": "2024-06-22T20:15:49.500325Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "dir = \"./data\"\n",
    "output_dir = \"./converted\"\n",
    "for f in os.listdir(dir):\n",
    "  fp = os.path.join(dir, f)\n",
    "\n",
    "  # prefalign\n",
    "  pa = prefalign(open(fp, 'r').read())\n",
    "  open(os.path.join(output_dir, f), 'w').write(pa)"
   ],
   "metadata": {
    "id": "pX1AzsZePZH7",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:16:32.842044Z",
     "start_time": "2024-06-22T20:15:51.382349Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLxkSRC9EyFc"
   },
   "source": [
    "## Load to Oxigraph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NSWj9oKWHvyq",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:18:41.923488Z",
     "start_time": "2024-06-22T20:18:41.638944Z"
    }
   },
   "source": [
    "# Setup the disk or memory store\n",
    "# Memory store is faster, but needs 24+ GB of memory\n",
    "store = pyoxigraph.Store(path=\"./store\")  #  this is disk store based, simply remove the path argument for memory store if you have enough\n",
    "mime_type = \"application/n-quads\"   # application/n-triples or application/n-quads if you are loading those from data raw"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load test set "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T20:35:50.835390Z",
     "start_time": "2024-06-22T20:31:08.001437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For testing, we might just load a set of files to test with.   The next section shows loading all the files\n",
    "testset = [\"./data/obis_release.nt\", \"./data/aquadocs_release.nt\", \"./data/oceanexperts_release.nt\"]\n",
    "\n",
    "for f in testset:\n",
    "    print(f\"Loading: {f}\")\n",
    "    store.load(open(f, 'rb'), mime_type, base_iri=None, to_graph=None)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/obis_release.nt\n",
      "Loading: ./data/aquadocs_release.nt\n",
      "Loading: ./data/oceanexperts_release.nt\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load All files\n"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wjyc-4xEE0AQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "06d792a9-f29f-40c4-8dc5-b314399f87de"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading: ./data/marinetraining_release.nt\n",
      "Loading: ./data/euroceanexperts_release.nt\n",
      "Loading: ./data/invemarinstitutions_release.nt\n",
      "Loading: ./data/obps_release.nt\n",
      "Loading: ./data/oceanexpert_release.nt\n",
      "Loading: ./data/invemarexperts_release.nt\n",
      "Loading: ./data/wod_release.nt\n",
      "Loading: ./data/invemartraining_release.nt\n",
      "Loading: ./data/edmo_release.nt\n",
      "Loading: ./data/cioos_release.nt\n",
      "Loading: ./data/euroceanevents_release.nt\n",
      "Loading: ./data/africaioc_release.nt\n",
      "Loading: ./data/pedp_release.nt\n",
      "Loading: ./data/inanodc_release.nt\n",
      "Loading: ./data/oceanexperts_release.nt\n",
      "Loading: ./data/aquadocs_release.nt\n",
      "Loading: ./data/oceanscape_release.nt\n",
      "Loading: ./data/rda_release.nt\n",
      "Loading: ./data/edmerp_release.nt\n",
      "Loading: ./data/pdh_release.nt\n",
      "Loading: ./data/obis_release.nt\n",
      "Loading: ./data/medin_release.nt\n",
      "Loading: ./data/invemarvessels_release.nt\n"
     ]
    }
   ],
   "source": [
    "# Load files from one of the above directories into your triplestore\n",
    "dir = \"./data\"  # either of data or converted depending on what you did above\n",
    "\n",
    "for f in os.listdir(dir):\n",
    "  fp = os.path.join(dir, f)\n",
    "  print(f\"Loading: {fp}\")\n",
    "  store.load(open(fp, 'rb'), mime_type, base_iri=None, to_graph=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SPARQL Query sections"
   ],
   "metadata": {
    "id": "LJ1TTRCWLcVR"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ic1_OjIUMej8",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:36:26.587966Z",
     "start_time": "2024-06-22T20:36:26.585979Z"
    }
   },
   "source": [
    "qtest = \"\"\"\tPREFIX schema: <https://schema.org/>\n",
    "SELECT ?s\n",
    "WHERE {\n",
    "  graph ?g {\n",
    "     ?s ?p ?o  .\n",
    "     }\n",
    " } LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "q1 = list(store.query(qtest))"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": "print(q1)",
   "metadata": {
    "id": "SEIwBxpLiTWR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "outputId": "f04923d8-8949-47ed-e88c-3c8dbf1077d6",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:36:52.622743Z",
     "start_time": "2024-06-22T20:36:52.620980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfoeg>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfoeg>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfodg>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfodg>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfodg>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfoe0>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfoe0>>, <QuerySolution s=<NamedNode value=https://gleaner.io/xid/genid/cog4ds3k59mc738sfoe0>>, <QuerySolution s=<NamedNode value=https://oceanexpert.org/institution/19393>>, <QuerySolution s=<NamedNode value=https://oceanexpert.org/institution/19393>>]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "qtypetype = \"\"\"\tPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX schema: <https://schema.org/>\n",
    "\n",
    "SELECT DISTINCT ?source ?type ?target ?sType ?tType\n",
    "WHERE {\n",
    "    graph ?g {\n",
    "        ?source a ?sType .\n",
    "        ?target a ?tType .\n",
    "        ?source ?type ?target .\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "q2 = list(store.query(qtypetype))"
   ],
   "metadata": {
    "id": "ydsiKZlSlNe9",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:38:15.778951Z",
     "start_time": "2024-06-22T20:37:46.306868Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "# print(q2)",
   "metadata": {
    "id": "0F5wXo8WlNM-",
    "ExecuteTime": {
     "end_time": "2024-06-22T20:39:10.983944Z",
     "start_time": "2024-06-22T20:39:10.982251Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "copied over, need to integrate\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:54:17.603217Z",
     "start_time": "2024-06-22T20:39:36.611299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# yeah, I get it...   don't iterate rows...  PR's welcome for this, being bad is too easy!\n",
    "# for index, row in nodes.iterrows():\n",
    "#    g.add_node(row['Id'])\n",
    "g = GraphML()\n",
    "g.directed = False\n",
    "\n",
    "for  r in q2:\n",
    "    n1 = g.add_node(r['source'])\n",
    "    # n1['name'] = row['name']\n",
    "\n",
    "    n2 = g.add_node(r['target'])\n",
    "    # n2['type'] = \"Funder\"\n",
    "    # n2['value'] = row['funding.name']\n",
    "\n",
    "    # n3 = g.add_node(row['ahash'])\n",
    "    # n3['type'] = \"Affiliation\"\n",
    "    # n3['value'] = row['affil']\n",
    "\n",
    "    e1 = g.add_edge(n1, n2)\n",
    "    # e2 = g.add_edge(n1, n3)\n",
    "    # e['predicate'] = row['type']"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# some code needed only in Google Colab if you run there\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-23T15:28:07.075621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fname = \"testGraphML.graphml\"\n",
    "parser = GraphMLParser()\n",
    "parser.write(g, fname)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "g = nx.read_graphml(\"testGraphML.graphml\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Sigma(\n",
    "    g,\n",
    "    node_size=g.degree,\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    node_metrics=['louvain'],\n",
    "    node_color='louvain',\n",
    "    start_layout=5,\n",
    "    edge_size=lambda u, v: g.degree(u) + g.degree(v),\n",
    "    edge_size_range=(0.5, 5),\n",
    "    label_font='cursive',\n",
    "    node_label_size=g.degree,\n",
    "    label_density=0\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
